{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A. Computational Method\n",
    "\n",
    "## Appendix A.1 Overview\n",
    "\n",
    "Let's take the HJB equation for pre technology and pre damage jump as an example\n",
    "\n",
    "\\begin{aligned}\n",
    "0 & = \\max_{i_k, i_j, \\mathcal{E}} \\min_{h_k, h_y, h_j, g, f_\\ell}\\left(\\frac{\\delta}{1-\\rho}\\right)\\left[\\left(\\frac{\\alpha-i_k-i_j-\\alpha \\phi_0\\left[1-\\frac{\\mathcal{E}}{\\beta_t \\alpha \\exp(k)}\\right]^{\\phi_1}}{\\exp (\\Phi)} \\exp(k)\\right)^{1-\\rho}-1\\right] \\\\\n",
    "& +\\frac{\\partial \\Phi}{\\partial k}\\left[\\mu_k+i_k-\\frac{\\kappa}{2} i_k^2-\\frac{\\left|\\sigma_k\\right|^2}{2}+\\sigma_k h_k\\right]+\\frac{\\partial^2 \\Phi}{\\partial k^2} \\frac{\\left|\\sigma_k\\right|^2}{2} \\\\\n",
    "& +\\frac{\\partial \\Phi}{\\partial y}\\left(\\frac{1}{M} \\sum_m^M q(x \\mid m) \\theta(m)+\\varsigma h_y\\right) \\mathcal{E}+\\frac{\\partial^2 \\Phi}{\\partial y^2} \\frac{|\\varsigma|^2}{2} \\mathcal{E}^2 \\\\\n",
    "& -\\left(\\left[\\lambda_1+\\lambda_2 y\\right]\\left(\\frac{1}{M} \\sum_m^M q(x \\mid m) \\theta(m)+\\varsigma h_y\\right) \\mathcal{E}+\\lambda_2 \\frac{|\\varsigma|^2}{2} \\mathcal{E}^2\\right) \\\\\n",
    "& +\\frac{\\partial \\Phi}{\\partial j}\\left(-\\zeta+\\psi_0\\left(i_j\\right)^{\\psi_1} \\exp \\left(\\psi_1 \\log K-\\psi_1 \\log J\\right)-\\frac{\\left|\\sigma_j\\right|^2}{2}+\\sigma_j h_j\\right)+\\frac{\\partial^2 \\Phi}{\\partial j^2} \\frac{\\left|\\sigma_j\\right|^2}{2} \\\\\n",
    "& +\\xi_g I_g(J)(1-g+g \\log g)+I_g(J) g\\left(\\Phi^{II}-\\Phi\\right) \\\\\n",
    "& +\\xi_d I_n(y) \\sum_{\\ell=1}^L \\pi_d^{\\ell}\\left(1-f_{\\ell}+f_{\\ell} \\log f_{\\ell}\\right)+I_n(y) \\sum_{\\ell=1}^L \\pi_d^{\\ell} f_{\\ell}\\left(\\Phi^{\\ell}-\\Phi\\right) \\\\\n",
    "& +\\xi_k \\frac{\\left|h_k\\right|^2}{2}+\\xi_c \\frac{\\left|h_y\\right|^2}{2}+\\xi_j \\frac{\\left|h_j\\right|^2}{2}+\\xi_a \\frac{1}{M} \\sum_m^M q(x \\mid m) \\log q(x \\mid m)\n",
    "\\end{aligned}\n",
    "\n",
    "which satisfies conditions to switch the order of max and min operator. \n",
    "\n",
    "Then, after exchanging the order of max and min operator, we deliver the solution, i.e. value function $\\Phi$, to this HJB equation resursively according to \n",
    "\n",
    "\n",
    "- Start with current value function $\\Phi^n$ where $n \\in \\{0,1, 2,\\ldots\\}$ is called iteration step. Specifically, $\\Phi^0$ is the initial guess of value function, which can be vital to success of algorithm. We solve the HJB equation and update value function $\\Phi^n$ to $\\Phi^{n+1}$ in two steps.\n",
    "\n",
    "    1. Take current value function $\\Phi^n$ as given, let's start with current distortion and jump misspecification $h_k^n, h_y^n, h_j^n, g^n, f_\\ell^n$ and solve optimal distortion and jump misspecification in two sub-steps. \n",
    "\n",
    "        1. Take value function $\\Phi^n$ and current distortion and jump misspecification $h_k^n, h_y^n, h_j^n, g^n, f_\\ell^n$ as given, we update optimal actions from $i_k^{n}, i_j^{n}, \\mathcal{E}^{n}$ to $i_k^{n+1}, i_j^{n+1}, \\mathcal{E}^{n+1}$ in a maximization problem.\n",
    "\n",
    "        2. With updated robustly optimal actions $i_k^{n+1}, i_j^{n+1}, \\mathcal{E}^{n+1}$ in hand, we update optimal distortion $h_k^{n+1}, h_y^{n+1}, h_j^{n+1}, g^{n+1}, f_\\ell^{n+1}$ by solving a minimization problem.\n",
    "\n",
    "    2. With updated robustly optimal actions and probability distortion, we finally can update value function $\\Phi^{n+1}$ via upwind scheme.\n",
    "\n",
    "- We obtain a convergent solution to the HJB equation when the difference between two subsequent iterations is very tiny as\n",
    "\n",
    "$$\n",
    "|\\Phi^{n+1}-\\Phi^{n}| < \\epsilon\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is set to be $10^{-7}$.\n",
    "\n",
    "\n",
    "## Appendix A.2 Solving the Optimization Problem\n",
    "\n",
    "### Appendix A.2.1 Maximization\n",
    "\n",
    "Solution process for $i_k$ is given as follows, of which the same logic can apply to other actions $i_j, \\mathcal{E}$ easily.\n",
    "\n",
    "First order condition for $i_k$ writes\n",
    "\n",
    "$$\n",
    "\\delta\\left(\\frac{\\alpha-i_k-i_j-\\alpha \\phi_0\\left[1-\\frac{\\mathcal{E}}{\\beta_t \\alpha \\exp(k)}\\right]^{\\phi_1}}{\\exp (\\Phi)} \\exp(k)\\right)^{-\\rho} \\frac{\\exp (k)}{\\exp (\\Phi)} = \\frac{d \\Phi}{dk}\\left(1-\\kappa i_k\\right)\n",
    "$$\n",
    "\n",
    "which is a highly non-linear equation of $i_k$ and doesn't admit a quasi-analytial solution.\n",
    "\n",
    "Cobweb algorithm states that given current value function and probability distortion, we can update current actions $i_k^{n}, i_j^{n}, \\mathcal{E}^{n}$ according to \n",
    "\n",
    "\n",
    "$$\n",
    "mu^{n} = \\frac{d \\Phi^n}{dk}\\left(1-\\kappa {i_k^{n+1}}'\\right)\n",
    "$$\n",
    "\n",
    "where we define \n",
    "\n",
    "$$\n",
    "mu^{n} \\doteq \\delta\\left(\\frac{\\alpha-i_k^{n}-i_j^{n}-\\alpha \\phi_0\\left[1-\\frac{\\mathcal{E}^{n}}{\\beta_t \\alpha \\exp(k)}\\right]^{\\phi_1}}{\\exp (\\Phi^n)} \\exp(k)\\right)^{-\\rho} \\frac{\\exp (k)}{\\exp (\\Phi^n)}\n",
    "$$\n",
    "\n",
    "And $i_k^{n+1}$ is computed with relaxation paramter $\\chi$ as\n",
    "\n",
    "$$\n",
    "i_k^{n+1} = \\chi i_k^{n} + (1-\\chi) {i_k^{n+1}}'\n",
    "$$\n",
    "\n",
    "\n",
    "### Appendix A.2.2 Minimization\n",
    "\n",
    "Solution process to probability distortions is simpler and we take that of $h_k$ as an example, of which the same logic can apply to other probability distortions $h_y, h_j, g, f_\\ell$.\n",
    "\n",
    "First order condition for $h_k$ is written as \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\Phi}{\\partial k} \\sigma_k = -\\xi_k h_k\n",
    "$$\n",
    "\n",
    "With given value function $\\Phi^n$, we can update $h_k^{n+1}$ according to \n",
    "\n",
    "$$\n",
    "h_k^{n+1} = - \\frac{1}{\\xi_k} \\frac{\\partial \\Phi^n}{\\partial k} \\sigma_k \n",
    "$$\n",
    "\n",
    "## Appendix A.3 Solving the Algebraic System\n",
    "\n",
    "Suppose we have three controled stochastic process $x_t, y_t, z_t$ as \n",
    "\n",
    "\\begin{aligned}\n",
    "d x_t &= \\mu^x(x,y,z,\\alpha) dt + \\sigma^{x}(x,y,z,\\alpha) dB^1_t \\\\\n",
    "d y_t &= \\mu^y(x,y,z,\\alpha) dt + \\sigma^{y}(x,y,z,\\alpha) dB^2_t \\\\\n",
    "d z_t &= \\mu^z(x,y,z,\\alpha) dt + \\sigma^{z}(x,y,z,\\alpha) dB^3_t \n",
    "\\end{aligned}\n",
    "\n",
    "where $B^1_t, B^2_t, B^3_t$ are three independent standard Brownian process.\n",
    "\n",
    "\n",
    "Let's consider a generalized time-independent three-dimensional HJB equation:\n",
    "\n",
    "\\begin{aligned}\n",
    "0= & \\max_{\\alpha} -\\delta v(x,y,z) + u(x,y,z,\\alpha)\\\\\n",
    "    & + \\mu^x(x,y,z,\\alpha) \\partial_x v(x,y,z) + \\frac{{\\sigma^x}(x,y,z,\\alpha)^2}{2}\\partial_{xx} v(x,y,z) \\\\\n",
    "    &+ \\mu^y(x,y,z,\\alpha) \\partial_y v(x,y,z) + \\frac{{\\sigma^y}(x,y,z,\\alpha)^2}{2}\\partial_{yy} v(x,y,z) \\\\\n",
    "    & + \\mu^z(x,y,z,\\alpha) \\partial_z v(x,y,z) + \\frac{{\\sigma^z}(x,y,z,\\alpha)^2}{2}\\partial_{zz} v(x,y,z)\n",
    "\\end{aligned}\n",
    "\n",
    "where $\\alpha$ is the set of controls in the HJB equation, $x,y,z$ are the state variables of value function $v$ and $u$ is the utility function.\n",
    "\n",
    "### Appendix A.3.1 False Transient Algorithm\n",
    "\n",
    "To mitigate the inherent instability of the non-linear HJB, we add a false transcient (time) dimension and solve it until convergence. And the new HJB equation is as \n",
    "\n",
    "\\begin{aligned}\n",
    "\\partial_t v(x,y,z,t)= & \\max_{\\alpha} -\\delta v(x,y,z, t) + u(x,y,z,\\alpha)\\\\\n",
    "    & + \\mu^x(x,y,z,\\alpha) \\partial_x v(x,y,z, t) + \\frac{{\\sigma^x}(x,y,z,\\alpha)^2}{2}\\partial_{xx} v(x,y,z, t) \\\\\n",
    "    &+ \\mu^y(x,y,z,\\alpha) \\partial_y v(x,y,z, t) + \\frac{{\\sigma^y}(x,y,z,\\alpha)^2}{2}\\partial_{yy} v(x,y,z, t) \\\\\n",
    "    & + \\mu^z(x,y,z,\\alpha) \\partial_z v(x,y,z, t) + \\frac{{\\sigma^z}(x,y,z,\\alpha)^2}{2}\\partial_{zz} v(x,y,z, t)\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "\n",
    "### Appendix A.3.2 Finite-Difference Scheme\n",
    "\n",
    "#### Appendix A.3.2.1 Upwind Scheme\n",
    "\n",
    "\n",
    "Accordingly, we construct equispaced grids for these three state variable $x,y,z$ as \n",
    "\n",
    "\\begin{aligned}\n",
    "X &= \\{x_1=\\underline{X},\\ldots,x_N=\\bar{X}\\} \\\\\n",
    "Y &= \\{y_1=\\underline{Y},\\ldots,y_N=\\bar{Y}\\} \\\\\n",
    "Z &= \\{z_1=\\underline{Z},\\ldots,z_N=\\bar{Z}\\}\n",
    "\\end{aligned}\n",
    "\n",
    "where the distance between two grid points are $\\Delta x, \\Delta y, \\Delta z$\n",
    "\n",
    "We now approximate value function on grid points and use short-hand notation $v(x_i,y_j,z_k) \\doteq v_{i,j,k}$ and so on.\n",
    "\n",
    "The partial derivatives $\\partial_x v(x,y,z)$ can be approximated with either a forward or backward difference approximation\n",
    "\n",
    "\\begin{aligned}\n",
    "\\partial_{x,F} v_{i,j,k} &=  \\frac{v_{i+1,j,k}-v_{i,j,k}}{\\Delta x} \\\\\n",
    "\\partial_{x,B} v_{i,j,k} &=  \\frac{v_{i,j,k}-v_{i-1,j,k}}{\\Delta x} \n",
    "\\end{aligned}\n",
    "\n",
    "For accuracy, we decide to approximate the partial derivatives $\\partial_x v(x,y,z)$ via central difference approximation \n",
    "\n",
    "\\begin{aligned}\n",
    "\\partial_{x,C} v_{i,j,k} &=  \\frac{v_{i+1,j,k} - v_{i-1,j,k}}{2\\Delta x} \n",
    "\\end{aligned}\n",
    "\n",
    "which is an average of forward and backward difference approximation.\n",
    "\n",
    "Then, we approximate the second-order partial derivatives $\\partial_{xx} v(x,y,z)$ with a central difference approximation \n",
    "\n",
    "\\begin{aligned}\n",
    "\\partial_{xx} v_{i,j,k} &=  \\frac{v_{i+1,j,k} + v_{i-1,j,k}- 2v_{i,j,k}}{\\Delta x^2} \n",
    "\\end{aligned}\n",
    "\n",
    "We can employ the first-order-condition to express our control $\\alpha$ on a grid point $x_i, y_j, z_k$ as a nonlinear function of value function approximations $\\partial_{x,C} v_{i,j,k}$ and $\\partial_{xx} v_{i,j,k} $. Therefore, we use short-hand notations for our control, drift and diffusion term as\n",
    "\n",
    "\\begin{aligned}\n",
    "\\alpha(x_i,y_j,z_k) &= \\alpha_{i,j,k} \\\\\n",
    "u(x_i,y_j,z_k,\\alpha(x_i,y_j,z_k)) &= u_{i,j,k} \\\\\n",
    "\\mu^w(x_i,y_j,z_k,\\alpha(x_i,y_j,z_k)) &= \\mu^w_{i,j,k}, \\quad w=x,y,z\\\\\n",
    "\\sigma^w(x_i,y_j,z_k,\\alpha(x_i,y_j,z_k)) &= \\sigma^w_{i,j,k}, \\quad w=x,y,z\\\\\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "We use upwind scheme and construct backward approximation with negative drift and forward approximation with positive drift.\n",
    "\n",
    "To sum up, starting with current value function $v^{n}$, we update $v^{n+1}$ according to \n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{v^{n+1}_{i,j,k} - v^{n}_{i,j,k}}{\\Delta t} = &  -\\delta v^{n+1}_{i,j,k} + u_{i,j,k}^{n} \\\\\n",
    "    & + {\\mu^{x,n}_{i,j,k}}^{+} \\partial_x v^{n+1,F}_{i,j,k} + {\\mu^{x,n}_{i,j,k}}^{-}  \\partial_x v^{n+1,B}_{i,j,k}+ \\frac{{\\sigma^{x,n}_{i,j,k}}^2}{2}\\partial_{xx} v_{i,j,k}^{n+1}\\\\\n",
    "    & + {\\mu^{y,n}_{i,j,k}}^{+} \\partial_y v^{n+1,F}_{i,j,k} + {\\mu^{y,n}_{i,j,k}}^{-}  \\partial_y v^{n+1,B}_{i,j,k}+ \\frac{{\\sigma^{y,n}_{i,j,k}}^2}{2}\\partial_{yy} v_{i,j,k}^{n+1}\\\\\n",
    "    & + {\\mu^{z,n}_{i,j,k}}^{+} \\partial_z v^{n+1,F}_{i,j,k} + {\\mu^{z,n}_{i,j,k}}^{-}  \\partial_z v^{n+1,B}_{i,j,k}+ \\frac{{\\sigma^{z,n}_{i,j,k}}^2}{2}\\partial_{zz} v_{i,j,k}^{n+1}\\\\\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "#### A.3.2.2 Natural Boundary Condition\n",
    "\n",
    "We approximate second order derivative at boundaries with natural boundary condition. More specifically, suppose state variable $x$ is at its upper boundary, we set second order derivative of value function to be the same as that of closet inner point.\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "\\partial_{xx} v^{n+1}_{N,j,k} &=  \\partial_{xx} v^{n+1}_{N-1,j,k} = \\frac{v^{n+1}_{N,j,k} + v^{n+1}_{N-2,j,k}- 2v^{n+1}_{N-1,j,k}}{\\Delta x^2} \n",
    "\\end{aligned}\n",
    "\n",
    "Now the matrix notation of HJB equation can be written as\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{1}{\\Delta t} (v^{n+1}-v^{n}) + \\delta v^{n+1} = u^{n} + A^{n} v^{n+1}\n",
    "\\end{aligned}\n",
    "\n",
    "#### A.3.2.3 Implicit Euler\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A.4 List of Parameters Chosen in Algorithm\n",
    "\n",
    "| Parameter | Value |\n",
    "| :-- | :-- |\n",
    "|$\\chi$ | 0.0025 |\n",
    "|$\\Delta t$ | 0.0025 |\n",
    "| $\\underline{\\log K}$ | 4.0 |\n",
    "| $\\overline{\\log K}$ | 9.0 |\n",
    "| $\\underline{Y}$ | 0.0 |\n",
    "| $\\overline{Y}$ | 4.0 |\n",
    "| $\\underline{\\log J}$ | 1.0 |\n",
    "| $\\overline{\\log J}$ | 6.0 |\n",
    "| $\\Delta \\log K$ | 0.2 |\n",
    "| $\\Delta Y$ | 0.1 |\n",
    "| $\\Delta \\log J$ | 0.1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Appendix A.2 Cobweb Relaxation\n",
    "\n",
    "### Appendix A.2.1 A Deep Look into First Order Condition\n",
    "\n",
    "There are HJB equations with simple control dynamics. For example, this HJB equation, describing heterogenous agents model in Aiyagari-Bewley-Huggett Economy, \n",
    "\n",
    "$$\n",
    "\\rho v(a, z)=\\max _c u(c)+\\partial_a v(a, z)(z+r a-c)+\\mu(z) \\partial_z v(a, z)+\\frac{\\sigma^2(z)}{2} \\partial_{z z} v(a, z)\n",
    "$$\n",
    "\n",
    "has a very straight-forward optimal consumption choice as\n",
    "\n",
    "$$\n",
    "c^* = u^{\\prime-1}\\left(\\partial_a v(a, z)\\right)\n",
    "$$\n",
    "\n",
    "However, our HJB equations doesn't contain such simple dynamics. To solve a very complex system, we resort to a special algorithm called Cobweb algorithm. As it will show, the key idea is to reduce the non-linearity of the first order condition by progressively solving it in multiple steps.\n",
    "\n",
    "### Appendix A.2.1 Progressive Algorithm against Strong Non-linearity\n",
    "\n",
    "We take the HJB equation for post technology jump as an example.\n",
    "\n",
    "\\begin{aligned}\n",
    "0= & \\max_{i_k}\\min_{h_k} \\left(\\frac{\\delta}{1-\\rho}\\right)\\left[\\left(\\frac{\\alpha-i_k}{\\exp (v)} \\exp(k)\\right)^{1-\\rho}-1\\right] \\\\\n",
    "& +\\frac{d v}{dk}\\left[\\mu_k+i_k-\\frac{\\kappa}{2} i_k^2-\\frac{\\left|\\sigma_k\\right|^2}{2}+\\sigma_k h_k\\right]+\\frac{d^2 v}{d k^2} \\frac{\\left|\\sigma_k\\right|^2}{2} \\\\\n",
    "& +\\xi_k \\frac{\\left|h_k\\right|^2}{2}\n",
    "\\end{aligned}\n",
    "\n",
    "First order condition for $i_k$ writes\n",
    "\n",
    "$$\n",
    "\\delta\\left(\\frac{\\alpha-i_k}{\\exp (v)} \\exp (k)\\right)^{-\\rho} \\frac{\\exp (k)}{\\exp (v)} = \\frac{d v}{dk}\\left(1-\\kappa i_k\\right)\n",
    "$$\n",
    "\n",
    "which is a highly nonlinear equation of $i_k$ and doesn't lead to a quasi-analytical solution.\n",
    "\n",
    "To get around the nonlinearity, the Cobweb algorithm states that we define a new term $mu$ as\n",
    "\n",
    "$$\n",
    "m u=\\frac{d v}{dk}\\left(1-\\kappa i_k\\right)\n",
    "$$\n",
    "\n",
    "Then we solve the equation in multiple steps. Starting with a initial guess of $i_k$ as $i_k^0$, we update $i_k^n$, $n=1,2,\\ldots,N$ according to \n",
    "\n",
    "$$\n",
    "mu^{n}= \\frac{d v}{dk}\\left(1-\\kappa i_k^{n+1}\\right)\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "mu^{n} = \\delta\\left(\\frac{\\alpha-i_k^n}{\\exp (v)} \\exp (k)\\right)^{-\\rho} \\frac{\\exp (k)}{\\exp (v)}\n",
    "$$\n",
    "\n",
    "\n",
    "Now, to decide when to stop, we hope to see the difference between two subsequent iterations very tiny, meaning we have obtained a convergent solution to the equation. In other words, we wish to see\n",
    "\n",
    "$$\n",
    "|i_k^n-i_k^{n-1}| < \\epsilon\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is set to be $10^{-7}$.\n",
    "\n",
    "\n",
    "### Appendix A.2.3 Further Improvement\n",
    "\n",
    "While the Cobweb algorithm can alleviate our computational burden of dealing with complex first order conditions a lot, there is still much room for further improvement on efficiency of our algorithm. For example, as we notice that the main purpose is to deliver a convergent solution to the value function in the HJB equation, we can alternate the Cobweb algorithm in a way that it's iterating not over control, such as $i_k$, but directly over value function.\n",
    "\n",
    "In other words, we start with initial guess of $v$, $i_k$ as $v^0$, $i_k^0$ and complete a inner iteration over $i_k$ and an outer iteration over $v$. \n",
    "\n",
    "In the inner iteration, we take value function $v^n$ as given and attempt to update $i_k^n$ according to \n",
    "\n",
    "$$\n",
    "mu^{n}= \\frac{d v^{n}}{dk}\\left(1-\\kappa {i_k^{n+1}}'\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "mu^{n}= \\delta\\left(\\frac{\\alpha-i_k^{n}}{\\exp (v^{n})} \\exp (k)\\right)^{-\\rho} \\frac{\\exp (k)}{\\exp (v^{n})}\n",
    "$$\n",
    "\n",
    "Here we progressively update $i_k^n$ to $i_k^{n+1}$ by a convex combination of $i_k^n$ and ${i_k^{n+1}}'$ with a relaxation parameter $\\chi$ as\n",
    "\n",
    "$$\n",
    "i_k^{n+1}= \\chi i_k^n + (1-\\chi) {i_k^{n+1}}'.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Once we have updated $i_k^{n+1}$, we can turn to outer iteration that updating $v^{n+1}$ according to \n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "0= &  \\left(\\frac{\\delta}{1-\\rho}\\right)\\left[\\left(\\frac{\\alpha-i_k^{n+1}}{\\exp (v^{n})} \\exp(k)\\right)^{1-\\rho}-1\\right] \\\\\n",
    "& +\\frac{d v^{n+1}}{dk}\\left[\\mu_k+{i_k^{n+1}}-\\frac{\\kappa}{2} {i_k^{n+1}}^2-\\frac{\\left|\\sigma_k\\right|^2}{2}+\\sigma_k {h_k^{n+1}}\\right]+\\frac{d^2 v^{n+1}}{d k^2} \\frac{\\left|\\sigma_k\\right|^2}{2} \\\\\n",
    "& +\\xi_k \\frac{\\left|{h_k^{n+1}}\\right|^2}{2}\n",
    "\\end{aligned}\n",
    "\n",
    "To sum up, this alternated Cobweb algorithm aims at achieving a very tiny difference between two subsequent iterations over value function $v$ more directly, \n",
    "\n",
    "$$\n",
    "|v^{n+1}-v^{n}| < \\epsilon\n",
    "$$\n",
    "\n",
    "which improved the efficiency and stability gallantly.\n",
    " -->\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
