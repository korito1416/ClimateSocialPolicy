{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16: Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.1 Numerical Method Demonstration\n",
    "\n",
    "As we discussed in section 3, there are two steps to do value decomposition:\n",
    "1. Simulate state variable processes and first variation processes.\n",
    "2. Calculated four terms of discounted social cash flow. \n",
    "While simulating state variables and first variational process instep (1) is case by case, step (2) is more general an one can use our general code in Quant MFR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Here we use finite difference method to calculate the derivatives with respect to state variables and the interpolate to get partial derivatives at every point. The derivative we need to calculate is\n",
    "\\begin{align}\n",
    "\\{\\frac{\\partial \\mu_i}{\\partial x}(x) ,    \\frac{\\partial \\sigma_i}{\\partial x}(x) , \\frac{\\partial V}{\\partial x}(x)  ,V^\\ell_x(X_t) , U_x(X_t) , {\\mathcal J}^{\\ell}_x(X_t)      \\}\n",
    "\\end{align}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_pre(data, Data_Dir, File_Dir):\n",
    "\n",
    "    ...\n",
    "    '''Finite Differenc Method to calculate derivetives needed in value decomposition'''\n",
    "    df_U_m1 = finiteDiff_4D(df_U,0,1,wscale)\n",
    "    df_U_m2 = finiteDiff_4D(df_U,1,1,zscale)\n",
    "    df_U_m3 = finiteDiff_4D(df_U,2,1,vscale)\n",
    "    df_U_m4 = finiteDiff_4D(df_U,3,1,xscale)\n",
    "\n",
    "    df_J1_m1 = finiteDiff_4D(J1,0,1,wscale)\n",
    "    df_J2_m2 = finiteDiff_4D(J2,1,1,zscale)\n",
    "    df_J3_m3 = finiteDiff_4D(J3,2,1,vscale)\n",
    "    df_J4_m4 = finiteDiff_4D(J4,3,1,vscale)\n",
    " \n",
    "    df_V1_m1 = finiteDiff_4D(V1,0,1,wscale)\n",
    "    df_V1_m2 = finiteDiff_4D(V1,1,1,zscale)\n",
    "    df_V1_m3 = finiteDiff_4D(V1,2,1,vscale)\n",
    "    df_V1_m4 = finiteDiff_4D(V1,3,1,xscale)\n",
    "\n",
    "\n",
    "\n",
    "    df_V2_m1 = np.zeros_like(V2)\n",
    "    df_V2_m2 = np.zeros_like(V2)\n",
    "    df_V2_m3 = np.zeros_like(V2)\n",
    "    df_V2_m4 = np.zeros_like(V2)\n",
    "\n",
    " \n",
    "    df_f_damage_m1 = np.zeros_like(f_damage)\n",
    "    df_f_damage_m2 = np.zeros_like(f_damage)\n",
    "    df_f_damage_m3 = np.zeros_like(f_damage)\n",
    "    df_f_damage_m4 = np.zeros_like(f_damage)\n",
    "\n",
    "    for i in range(n_damage):\n",
    "\n",
    "        \n",
    "        df_V2_m1_slice = finiteDiff_4D(V2[i,:,:,:,:],0,1,wscale)\n",
    "        df_V2_m2_slice = finiteDiff_4D(V2[i,:,:,:,:],1,1,zscale)\n",
    "        df_V2_m3_slice = finiteDiff_4D(V2[i,:,:,:,:],2,1,vscale)\n",
    "        df_V2_m4_slice = finiteDiff_4D(V2[i,:,:,:,:],3,1,xscale)\n",
    "\n",
    "        df_V2_m1[i,:,:,:,:] = df_V2_m1_slice\n",
    "        df_V2_m2[i,:,:,:,:] = df_V2_m2_slice\n",
    "        df_V2_m3[i,:,:,:,:] = df_V2_m3_slice\n",
    "        df_V2_m4[i,:,:,:,:] = df_V2_m4_slice\n",
    "\n",
    "\n",
    "        \n",
    "        df_f_damage_m1_slice = finiteDiff_4D(f_damage[i,:,:,:,:],0,1,wscale)\n",
    "        df_f_damage_m2_slice = finiteDiff_4D(f_damage[i,:,:,:,:],1,1,zscale)\n",
    "        df_f_damage_m3_slice = finiteDiff_4D(f_damage[i,:,:,:,:],2,1,vscale)\n",
    "        df_f_damage_m4_slice = finiteDiff_4D(f_damage[i,:,:,:,:],3,1,xscale)\n",
    "\n",
    "        df_f_damage_m1[i,:,:,:,:] = df_f_damage_m1_slice\n",
    "        df_f_damage_m2[i,:,:,:,:] = df_f_damage_m2_slice\n",
    "        df_f_damage_m3[i,:,:,:,:] = df_f_damage_m3_slice\n",
    "        df_f_damage_m4[i,:,:,:,:] = df_f_damage_m4_slice\n",
    "\n",
    "    df_f_tech_m1 = finiteDiff_4D(f_tech,0,1,wscale)\n",
    "    df_f_tech_m2 = finiteDiff_4D(f_tech,1,1,zscale)\n",
    "    df_f_tech_m3 = finiteDiff_4D(f_tech,2,1,vscale)\n",
    "    df_f_tech_m4 = finiteDiff_4D(f_tech,3,1,xscale)\n",
    "\n",
    "\n",
    "    df_V3_m1 = finiteDiff_4D(V3,0,1,wscale)\n",
    "    df_V3_m2 = finiteDiff_4D(V3,1,1,zscale)\n",
    "    df_V3_m3 = finiteDiff_4D(V3,2,1,vscale)\n",
    "    df_V3_m4 = finiteDiff_4D(V3,3,1,xscale)\n",
    "\n",
    "    df_V4_m1 = finiteDiff_4D(V4,0,1,wscale)\n",
    "    df_V4_m2 = finiteDiff_4D(V4,1,1,zscale)\n",
    "    df_V4_m3 = finiteDiff_4D(V4,2,1,vscale)\n",
    "    df_V4_m4 = finiteDiff_4D(V4,3,1,xscale)\n",
    "\n",
    "    df_V_m1 = finiteDiff_4D(Va,0,1,wscale)\n",
    "    df_V_m2 = finiteDiff_4D(Va,1,1,zscale)\n",
    "    df_V_m3 = finiteDiff_4D(Va,2,1,vscale)\n",
    "    df_V_m4 = finiteDiff_4D(Va,3,1,xscale)\n",
    "    df_muW_interpolated = RGI([W_unique,Z_unique, V_unique, X_unique], df_muW_reshaped, fill_value=None, bounds_error=True)\n",
    "    df_muZ_interpolated = RGI([W_unique,Z_unique, V_unique, X_unique], df_muZ_reshaped, fill_value=None, bounds_error=True)\n",
    "    df_muV_interpolated = RGI([W_unique,Z_unique, V_unique, X_unique], df_muV_reshaped, fill_value=None, bounds_error=True)\n",
    "    df_muX_interpolated = RGI([W_unique,Z_unique, V_unique, X_unique], df_muX_reshaped, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_muW_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muW_reshaped_m1, fill_value=None, bounds_error=True)\n",
    "    df_muW_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muW_reshaped_m2, fill_value=None, bounds_error=True)\n",
    "    df_muW_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muW_reshaped_m3, fill_value=None, bounds_error=True)\n",
    "    df_muW_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muW_reshaped_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_muZ_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muZ_reshaped_m1, fill_value=None, bounds_error=True)\n",
    "    df_muZ_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muZ_reshaped_m2, fill_value=None, bounds_error=True)\n",
    "    df_muZ_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muZ_reshaped_m3, fill_value=None, bounds_error=True)\n",
    "    df_muZ_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muZ_reshaped_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_muV_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muV_reshaped_m1, fill_value=None, bounds_error=True)\n",
    "    df_muV_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muV_reshaped_m2, fill_value=None, bounds_error=True)\n",
    "    df_muV_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muV_reshaped_m3, fill_value=None, bounds_error=True)\n",
    "    df_muV_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muV_reshaped_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_muX_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muX_reshaped_m1, fill_value=None, bounds_error=True)\n",
    "    df_muX_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muX_reshaped_m2, fill_value=None, bounds_error=True)\n",
    "    df_muX_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muX_reshaped_m3, fill_value=None, bounds_error=True)\n",
    "    df_muX_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_muX_reshaped_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_sigmaW0_interpolated = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaW0_reshaped, fill_value=None, bounds_error=True)\n",
    "    df_sigmaZ0_interpolated = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaZ0_reshaped, fill_value=None, bounds_error=True)\n",
    "    df_sigmaV0_interpolated = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaV0_reshaped, fill_value=None, bounds_error=True)\n",
    "    df_sigmaX0_interpolated = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaX0_reshaped, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_sigmaW0_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaW0_reshaped_m1, fill_value=None, bounds_error=True)\n",
    "    df_sigmaW0_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaW0_reshaped_m2, fill_value=None, bounds_error=True)\n",
    "    df_sigmaW0_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaW0_reshaped_m3, fill_value=None, bounds_error=True)\n",
    "    df_sigmaW0_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaW0_reshaped_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_sigmaZ0_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaZ0_reshaped_m1, fill_value=None, bounds_error=True)\n",
    "    df_sigmaZ0_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaZ0_reshaped_m2, fill_value=None, bounds_error=True)\n",
    "    df_sigmaZ0_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaZ0_reshaped_m3, fill_value=None, bounds_error=True)\n",
    "    df_sigmaZ0_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaZ0_reshaped_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_sigmaV0_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaV0_reshaped_m1, fill_value=None, bounds_error=True)\n",
    "    df_sigmaV0_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaV0_reshaped_m2, fill_value=None, bounds_error=True)\n",
    "    df_sigmaV0_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaV0_reshaped_m3, fill_value=None, bounds_error=True)\n",
    "    df_sigmaV0_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaV0_reshaped_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_sigmaX0_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaX0_reshaped_m1, fill_value=None, bounds_error=True)\n",
    "    df_sigmaX0_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaX0_reshaped_m2, fill_value=None, bounds_error=True)\n",
    "    df_sigmaX0_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaX0_reshaped_m3, fill_value=None, bounds_error=True)\n",
    "    df_sigmaX0_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_sigmaX0_reshaped_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    "    df_U_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_U_m1, fill_value=None, bounds_error=True)\n",
    "    df_U_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_U_m2, fill_value=None, bounds_error=True)\n",
    "    df_U_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_U_m3, fill_value=None, bounds_error=True)\n",
    "    df_U_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_U_m4, fill_value=None, bounds_error=True)\n",
    "\n",
    " \n",
    "    df_Entropy_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_Entropy_dx1, fill_value=None, bounds_error=True)\n",
    "    df_Entropy_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_Entropy_dx2, fill_value=None, bounds_error=True)\n",
    "    df_Entropy_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_Entropy_dx3, fill_value=None, bounds_error=True)\n",
    "    df_Entropy_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_Entropy_dx4, fill_value=None, bounds_error=True)\n",
    "\n",
    " \n",
    "    df_J1_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_J1_m1, fill_value=None, bounds_error=True)\n",
    "    df_J2_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_J2_m2, fill_value=None, bounds_error=True)\n",
    "    df_J3_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_J3_m3, fill_value=None, bounds_error=True)\n",
    "    df_J4_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_J4_m4, fill_value=None, bounds_error=True)\n",
    "    \n",
    "    df_V1_interpolated_m1 = RGI([W_unique,Z_unique, V_unique, X_unique], df_V1_m1, fill_value=None, bounds_error=True)\n",
    "    df_V1_interpolated_m2 = RGI([W_unique,Z_unique, V_unique, X_unique], df_V1_m2, fill_value=None, bounds_error=True)\n",
    "    df_V1_interpolated_m3 = RGI([W_unique,Z_unique, V_unique, X_unique], df_V1_m3, fill_value=None, bounds_error=True)\n",
    "    df_V1_interpolated_m4 = RGI([W_unique,Z_unique, V_unique, X_unique], df_V1_m4, fill_value=None, bounds_error=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we could start for loop from time 0 to recursively get four discounted term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(N-1): \n",
    "    muW_t = df_muW_interpolated([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "    sigmaW0_t = df_sigmaW0_interpolated([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "    \n",
    "    muZ_t = df_muZ_interpolated([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "    sigmaZ0_t = df_sigmaZ0_interpolated([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "    \n",
    "    muV_t = df_muV_interpolated([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "    sigmaV0_t = df_sigmaV0_interpolated([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "\n",
    "    muX_t = df_muX_interpolated([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "    sigmaX0_t = df_sigmaX0_interpolated([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "\n",
    "    mu_m1_t = m1_process[t]*df_muW_interpolated_m1([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m2_process[t]*df_muW_interpolated_m2([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m3_process[t]*df_muW_interpolated_m3([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m4_process[t]*df_muW_interpolated_m4([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "\n",
    "    sigma_m1_t = m1_process[t]*df_sigmaW0_interpolated_m1([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m2_process[t]*df_sigmaW0_interpolated_m2([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m3_process[t]*df_sigmaW0_interpolated_m3([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m4_process[t]*df_sigmaW0_interpolated_m4([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "                \n",
    "    mu_m2_t = m1_process[t]*df_muZ_interpolated_m1([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m2_process[t]*df_muZ_interpolated_m2([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m3_process[t]*df_muZ_interpolated_m3([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m4_process[t]*df_muZ_interpolated_m4([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "                \n",
    "    sigma_m2_t = m1_process[t]*df_sigmaZ0_interpolated_m1([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m2_process[t]*df_sigmaZ0_interpolated_m2([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m3_process[t]*df_sigmaZ0_interpolated_m3([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m4_process[t]*df_sigmaZ0_interpolated_m4([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "                \n",
    "    mu_m3_t = m1_process[t]*df_muV_interpolated_m1([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m2_process[t]*df_muV_interpolated_m2([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m3_process[t]*df_muV_interpolated_m3([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m4_process[t]*df_muV_interpolated_m4([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "\n",
    "    sigma_m3_t = m1_process[t]*df_sigmaV0_interpolated_m1([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m2_process[t]*df_sigmaV0_interpolated_m2([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m3_process[t]*df_sigmaV0_interpolated_m3([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m4_process[t]*df_sigmaV0_interpolated_m4([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "    \n",
    "\n",
    "    mu_m4_t = m1_process[t]*df_muX_interpolated_m1([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m2_process[t]*df_muX_interpolated_m2([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m3_process[t]*df_muX_interpolated_m3([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m4_process[t]*df_muX_interpolated_m4([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "\n",
    "    sigma_m4_t = m1_process[t]*df_sigmaX0_interpolated_m1([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m2_process[t]*df_sigmaX0_interpolated_m2([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m3_process[t]*df_sigmaX0_interpolated_m3([w_process[t],z_process[t],v_process[t],x_process[t]])+\\\n",
    "                m4_process[t]*df_sigmaX0_interpolated_m4([w_process[t],z_process[t],v_process[t],x_process[t]])\n",
    "    \n",
    "\n",
    "\n",
    "    m1_process[t+1] = m1_process[t] + mu_m1_t*dt + W1[t]*sigma_m1_t\n",
    "    m2_process[t+1] = m2_process[t] + mu_m2_t*dt + W2[t]*sigma_m2_t\n",
    "    m3_process[t+1] = m3_process[t] + mu_m3_t*dt + W3[t]*sigma_m3_t\n",
    "    m4_process[t+1] = m4_process[t] + mu_m4_t*dt + W4[t]*sigma_m4_t\n",
    "            \n",
    "    w_process[t+1] = w_process[t] + muW_t*dt + W1[t]*sigmaW0_t \n",
    "    z_process[t+1] = z_process[t] + muZ_t*dt + W2[t]*sigmaZ0_t\n",
    "    v_process[t+1] = v_process[t] + muV_t*dt + W3[t]*sigmaV0_t\n",
    "    x_process[t+1] = x_process[t] + muX_t*dt + W4[t]*sigmaX0_t\n",
    "\n",
    "    u1_process[t+1] = df_U_interpolated_m1([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    u2_process[t+1] = df_U_interpolated_m2([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    u3_process[t+1] = df_U_interpolated_m3([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    u4_process[t+1] = df_U_interpolated_m4([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    " \n",
    "    j1_process[t+1] = df_J1_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    j2_process[t+1] = df_J2_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    j3_process[t+1] = df_J3_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    j4_process[t+1] = df_J4_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "\n",
    "    v1_process[t+1] = df_V1_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "\n",
    "    for i in range(n_damage):\n",
    "\n",
    "        v2_process[i,t+1] = df_V2_interpolated[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "        damage_process[i,t+1] = f_damage_interpolated[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "\n",
    "    tech_process[t+1] = f_tech_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "    Entropy_x1_process[t+1] = df_Entropy_interpolated_m1([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    Entropy_x2_process[t+1] = df_Entropy_interpolated_m2([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    Entropy_x3_process[t+1] = df_Entropy_interpolated_m3([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    Entropy_x4_process[t+1] = df_Entropy_interpolated_m4([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "    # v2_process[t+1] = df_V2_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "    v3_process[t+1] = df_V3_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    v4_process[t+1] = df_V4_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "    va_process[t+1] = df_V_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "    dj1_dx1_process[t+1] = df_J1_interpolated_m1([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dj2_dx2_process[t+1] = df_J2_interpolated_m2([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dj3_dx3_process[t+1] = df_J3_interpolated_m3([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dj4_dx4_process[t+1] = df_J4_interpolated_m4([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    \n",
    "    dv1_dx1_process[t+1] = df_V1_interpolated_m1([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv1_dx2_process[t+1] = df_V1_interpolated_m2([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv1_dx3_process[t+1] = df_V1_interpolated_m3([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv1_dx4_process[t+1] = df_V1_interpolated_m4([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "\n",
    "    for i in range(n_damage):\n",
    "        dv2_dx1_process[i,t+1] = df_V2_interpolated_m1[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "        dv2_dx2_process[i,t+1] = df_V2_interpolated_m2[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "        dv2_dx3_process[i,t+1] = df_V2_interpolated_m3[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "        dv2_dx4_process[i,t+1] = df_V2_interpolated_m4[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "\n",
    "        dfdamage_dx1_process[i,t+1] = df_f_damage_interpolated_m1[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "        dfdamage_dx2_process[i,t+1] = df_f_damage_interpolated_m2[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "        dfdamage_dx3_process[i,t+1] = df_f_damage_interpolated_m3[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "        dfdamage_dx4_process[i,t+1] = df_f_damage_interpolated_m4[i]([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "    dftech_dx1_process[t+1] = df_f_tech_m1_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dftech_dx2_process[t+1] = df_f_tech_m2_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dftech_dx3_process[t+1] = df_f_tech_m3_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dftech_dx4_process[t+1] = df_f_tech_m4_interpolated([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    " \n",
    "\n",
    "    dv3_dx1_process[t+1] = df_V3_interpolated_m1([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv3_dx2_process[t+1] = df_V3_interpolated_m2([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv3_dx3_process[t+1] = df_V3_interpolated_m3([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv3_dx4_process[t+1] = df_V3_interpolated_m4([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    \n",
    "    dv4_dx1_process[t+1] = df_V4_interpolated_m1([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv4_dx2_process[t+1] = df_V4_interpolated_m2([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv4_dx3_process[t+1] = df_V4_interpolated_m3([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv4_dx4_process[t+1] = df_V4_interpolated_m4([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    \n",
    "    dv_dx1_process[t+1] = df_V_interpolated_m1([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv_dx2_process[t+1] = df_V_interpolated_m2([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv_dx3_process[t+1] = df_V_interpolated_m3([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "    dv_dx4_process[t+1] = df_V_interpolated_m4([w_process[t+1],z_process[t+1],v_process[t+1],x_process[t+1]])\n",
    "\n",
    "\n",
    "\n",
    "    first_term[t+1] = u1_process[t+1]*m1_process[t+1]+\\\n",
    "                    u2_process[t+1]*m2_process[t+1]+\\\n",
    "                    u3_process[t+1]*m3_process[t+1]+\\\n",
    "                    u4_process[t+1]*m4_process[t+1]\n",
    " \n",
    "    second_term[t+1] = dj1_dx1_process[t+1]*(v1_process[t+1] - va_process[t+1])*m1_process[t+1]+\\\n",
    "                dj2_dx2_process[t+1]*np.mean(damage_process[:,t+1]*(v2_process[:,t+1] - va_process[t+1]),axis=0)*m2_process[t+1]+\\\n",
    "                dj3_dx3_process[t+1]*tech_process[t+1]*(v3_process[t+1] - va_process[t+1])*m3_process[t+1]+\\\n",
    "                dj4_dx4_process[t+1]*(v4_process[t+1] - va_process[t+1])*m4_process[t+1]\n",
    "    third_term_1[t+1] = j1_process[t+1]*(dv1_dx1_process[t+1])*m1_process[t+1]+\\\n",
    "                    j1_process[t+1]*(dv1_dx2_process[t+1])*m2_process[t+1]+\\\n",
    "                    j1_process[t+1]*(dv1_dx3_process[t+1])*m3_process[t+1]+\\\n",
    "                    j1_process[t+1]*(dv1_dx4_process[t+1])*m4_process[t+1]\n",
    " \n",
    "    third_term_2[t+1] = j2_process[t+1]*np.mean(damage_process[:,t+1]*dv2_dx1_process[:,t+1],axis=0)*m1_process[t+1]+\\\n",
    "                    j2_process[t+1]*np.mean(damage_process[:,t+1]*dv2_dx2_process[:,t+1],axis=0)*m2_process[t+1]+\\\n",
    "                    j2_process[t+1]*np.mean(damage_process[:,t+1]*dv2_dx3_process[:,t+1],axis=0)*m3_process[t+1]+\\\n",
    "                    j2_process[t+1]*np.mean(damage_process[:,t+1]*dv2_dx4_process[:,t+1],axis=0)*m4_process[t+1]\n",
    " \n",
    "    third_term_3[t+1] = j3_process[t+1]*tech_process[t+1]*(dv3_dx1_process[t+1])*m1_process[t+1]+\\\n",
    "                    j3_process[t+1]*tech_process[t+1]*(dv3_dx2_process[t+1])*m2_process[t+1]+\\\n",
    "                    j3_process[t+1]*tech_process[t+1]*(dv3_dx3_process[t+1])*m3_process[t+1]+\\\n",
    "                    j3_process[t+1]*tech_process[t+1]*(dv3_dx4_process[t+1])*m4_process[t+1]\n",
    "\n",
    "    third_term_4[t+1] = j4_process[t+1]*(dv4_dx1_process[t+1])*m1_process[t+1]+\\\n",
    "                    j4_process[t+1]*(dv4_dx2_process[t+1])*m2_process[t+1]+\\\n",
    "                    j4_process[t+1]*(dv4_dx3_process[t+1])*m3_process[t+1]+\\\n",
    "                    j4_process[t+1]*(dv4_dx4_process[t+1])*m4_process[t+1]\n",
    "    \n",
    " \n",
    "    fourth_term_entropy[t+1] = Entropy_x1_process[t+1]*m1_process[t+1]+\\\n",
    "                                Entropy_x2_process[t+1]*m2_process[t+1]+\\\n",
    "                                Entropy_x3_process[t+1]*m3_process[t+1]+\\\n",
    "                                Entropy_x4_process[t+1]*m4_process[t+1]\n",
    " \n",
    "    discount_factor_temps[t+1] =  -delta-j1_process[t+1]-j2_process[t+1]*np.mean(damage_process[:,t+1],axis=0)-j3_process[t+1]*tech_process[t+1]-j4_process[t+1]\n",
    "    discount_factor_temps_nodelta[t+1] =  -j1_process[t+1]-j2_process[t+1]*np.mean(damage_process[:,t+1],axis=0)-j3_process[t+1]*tech_process[t+1]-j4_process[t+1]\n",
    "\n",
    "    discount_factors[t+1] = discount_factors[t]+discount_factor_temps[t+1]*dt\n",
    "\n",
    "    discount_factor_nodelta_DisSep_Damage[t+1] = discount_factor_nodelta_DisSep_Damage[t]+(-j2_process[t+1]*np.mean(damage_process[:,t+1],axis=0))*dt\n",
    "    discount_factor_nodelta_DisSep_Tech[t+1] = discount_factor_nodelta_DisSep_Tech[t]+(-j3_process[t+1]*tech_process[t+1])*dt\n",
    "    discount_factor_nodelta[t+1] = discount_factor_nodelta[t]+discount_factor_temps_nodelta[t+1]*dt\n",
    "    \n",
    "    discount_factor_nodeltadt_DisSep_Damage[t+1] = -np.exp(discount_factor_nodelta[t+1]) * ( - j2_process[t+1]*np.mean(damage_process[:,t+1],axis=0)) \n",
    "    discount_factor_nodeltadt_DisSep_Tech[t+1] = -np.exp(discount_factor_nodelta[t+1]) * (  - j3_process[t+1]*tech_process[t+1]) \n",
    "    discount_factor_nodeltadt[t+1] = -np.exp(discount_factor_nodelta[t+1]) * discount_factor_temps_nodelta[t+1]\n",
    "    undiscount_process[t+1] = delta*first_term[t+1]+second_term[t+1]+third_term_1[t+1]+third_term_2[t+1]+third_term_3[t+1]+third_term_4[t+1]+fourth_term_entropy[t+1]\n",
    " \n",
    "    discount_process[t+1] = undiscount_process[t+1] * np.exp(discount_factors[t+1])\n",
    " \n",
    "    time_process[t+1] = time_process[t]+dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We primarily use above code to get the value decomposition results. In each iteraton step, we store calculate every term used in value decomposition. Alternative way is to get the entire simulated state variable and first variational path and then calculate remaining terms. We can use our generalized code for state varibable and impulse response simulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the partial derivatives, we can use general code showed below to parrellelize simulation and calculate the four terms of discounted social cashflow.  In our case, we don't have jumps, just use None for L_matrix. \n",
    "\n",
    " \n",
    "| **Variable**           | **Description**                                                                                      |\n",
    "|------------------------|------------------------------------------------------------------------------------------------------|\n",
    "| `X_matrix`             | `np.array` of shape `(sim_num, sim_time, 2)`. Stores the state variable \\( X_t \\) for each simulation run and time step. Each entry is an `np.array` representing \\( X_t \\). |\n",
    "| `M_matrix`             | `np.array` of shape `(sim_num, sim_time, 2)`. Stores the perturbation direction \\( M_t \\) for each simulation run and time step. Each entry is an `np.array` representing \\( M_t \\). |\n",
    "| `L_matrix`             | `np.array` of shape `(sim_num, sim_time)`. Stores the jump state \\( L_t \\) (as an integer) for each simulation run and time step. |\n",
    "| `U`                    | Value function of the state variable and hidden state \\( (X, L) \\).                                   |\n",
    "| `V`                    | Value function of the state variable and hidden state \\( (X, L) \\).                                   |\n",
    "| `U_x`                  | Derivative of \\( U \\).                                                                                |\n",
    "| `V_x`                  | Derivative of \\( V \\).                                                                                |\n",
    "| `delta_V`              | Function of state variable and hidden state \\( (X, L) \\).                                             |\n",
    "| `delta_U`              | Function of state variable and hidden state \\( (X, L) \\).                                             |\n",
    "| `drift_rest_diff`       | Derivative of `drift_rest`, function of state variable and hidden state \\( (X, L) \\).                |\n",
    "| `sim_length`           | Integer representing the number of time steps in the simulation.                                      |\n",
    "| `time_step`            | Float representing the length of each time step.                                                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_irf(X_matrix, M_matrix, L_matrix, U_x, V_x, delta_V, delta_U, drift_rest_diff, sim_length, time_step): \n",
    "    #########################################################################\n",
    "    # Use simulated state evolution and compose IRF \n",
    "    #########################################################################\n",
    "\n",
    "    #########################################################################\n",
    "    # X_matrix    - np.array of shape (sim_num, sim_time, 2). Stores the state \n",
    "    #               variable X_t for each simulation run and time step. Each \n",
    "    #               entry is an np.array representing X_t.\n",
    "    # M_matrix    - np.array of shape (sim_num, sim_time, 2). Stores the \n",
    "    #               perturbation direction M_t for each simulation run and \n",
    "    #               time step. Each entry is an np.array representing M_t.\n",
    "    # L_matrix    - np.array of shape (sim_num, sim_time). Stores the jump \n",
    "    #               state L_t (as an integer) for each simulation run and time step.\n",
    "    # U: value function of state variable and hidden state (X, L) \n",
    "    # V: value function of state variable and hidden state (X, L) \n",
    "    # U_x: derivative of U \n",
    "    # V_x: derivative of V \n",
    "    # delta_V: function of state variable and hidden state (X, L)\n",
    "    # delta_U: function of state variable and hidden state (X, L)\n",
    "    # drift_rest_diff: derivative of drift_rest, function of state variable and hidden state (X, L)\n",
    "    # sim_length - integer: number of time steps in simulation \n",
    "    # time_step - float: length of time step \n",
    "\n",
    "\n",
    "    discount_V = np.zeros(np.shape(L_matrix)) \n",
    "    discount_U = np.zeros(np.shape(L_matrix)) \n",
    "    drift_rest_diff_series = np.zeros(np.shape(X_matrix)) \n",
    "    Ux_series = np.zeros(np.shape(X_matrix)) \n",
    "    Vx_series = np.zeros(np.shape(X_matrix)) \n",
    "    discount_V_t = [0 for i in range(len(L_matrix))] \n",
    "\n",
    "    dt = time_step \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = {executor.submit(compute_time_step, t, delta_V, delta_U, X_matrix, L_matrix, drift_rest_diff, U_x, V_x): t for t in range(sim_length)}\n",
    "        results = []\n",
    "        for future in tqdm(as_completed(futures), total=sim_length, desc=\"Processing tasks\"): \n",
    "            try:\n",
    "                result = future.result()  # Get the result from the future\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing time step {futures[future]}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Sort results by time step to ensure correct order\n",
    "    results.sort(key=lambda x: x[0]) \n",
    "\n",
    "    for t, discount_V_increment, discount_U_increment, drift_rest_diff_t, U_xt, V_xt in results:\n",
    "        discount_V_t += discount_V_increment * dt \n",
    "        discount_U_t = discount_U_increment\n",
    "        drift_rest_diff_series_t = drift_rest_diff_t\n",
    "        discount_V[:, t] = np.exp(discount_V_t) \n",
    "        discount_U[:, t] = discount_U_t \n",
    "        drift_rest_diff_series[:, t] = drift_rest_diff_series_t\n",
    "        Ux_series[:, t] = U_xt  \n",
    "        Vx_series[:, t] = V_xt  \n",
    "    \n",
    "    # Compute rhs and drhs across all simulations and time points\n",
    "    rhs = (discount_V * (np.sum(drift_rest_diff_series * Vx_series * M_matrix, axis = 2) * dt + discount_U * np.sum(Ux_series * M_matrix, axis = 2) * dt\n",
    "                        )).sum(axis=1) \n",
    "    drhs = (discount_V * (np.sum(drift_rest_diff_series * Vx_series * M_matrix, axis = 2) * dt + discount_U * np.sum(Ux_series * M_matrix, axis = 2) * dt\n",
    "                        ))\n",
    "    \n",
    "    # Append or sum for initial values and aggregated results\n",
    "    sdf1 = discount_V * discount_U * Ux_series[:, :, 0] \n",
    "    \n",
    "    # Compute means\n",
    "    mean_drhs = np.mean(drhs, axis=0)\n",
    "    mean_sdf1 = np.mean(sdf1, axis=0)\n",
    "    mean_return1 = np.mean(M_matrix, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    return rhs, mean_drhs, mean_sdf1, mean_return1 \n",
    "\n",
    "\n",
    "def compute_time_step(t, delta_V, delta_U, X_matrix, L_matrix, drift_rest_diff, U_x, V_x): \n",
    "    discount_V_increment = np.array([delta_V(X_matrix[i][t], L_matrix[i][t]) for i in range(len(L_matrix))]) \n",
    "    discount_U_increment = np.array([delta_U(X_matrix[i][t], L_matrix[i][t]) for i in range(len(L_matrix))]) \n",
    "    drift_rest_diff_t = np.array([drift_rest_diff(X_matrix[i][t], L_matrix[i][t]) for i in range(len(L_matrix))]) \n",
    "    U_xt = np.array([U_x(X_matrix[i][t], L_matrix[i][t]) for i in range(len(L_matrix))])  \n",
    "    V_xt = np.array([V_x(X_matrix[i][t], L_matrix[i][t]) for i in range(len(L_matrix))])  \n",
    "\n",
    "    return t, discount_V_increment, discount_U_increment, drift_rest_diff_t, U_xt, V_xt  # Return a tuple directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below code uses the law of motion of state variables to simulate the evolution of state variables and their response to an initial perturbation in one state using different random seeds.\n",
    " \n",
    "### Input\n",
    "| **Variable**   | **Description**                                                                                           |\n",
    "|----------------|-----------------------------------------------------------------------------------------------------------|\n",
    "| `lom`          | Function: Law of motion for \\( X_t \\) and \\( M_t \\). The next states, \\( X_{t+1} \\) and \\( M_{t+1} \\), are determined by `lom(X_t, M_t, W_t, L_t)`. |\n",
    "| `drift_adj`    | Function: Drift distortion function. Determines the drift term \\( \\mu_t \\), given by `drift_adj(X_t, L_t)`. |\n",
    "| `P_trans`      | Function: Transition probability for \\( L_t \\). The transition probability \\( P \\) is given by `P_trans(X_t, W_t)`. |\n",
    "| `X0`           | `np.array`: Initial state of the state variable \\( X_t \\).                                                |\n",
    "| `M0`           | `np.array`: Initial perturbation direction vector.                                                        |\n",
    "| `L0`           | Integer: Initial state of the jump variable \\( L_t \\).                                                    |\n",
    "| `num_shock`    | Integer: Dimension of the shock variable \\( W_t \\).                                                       |\n",
    "| `sim_time`     | Float: Total time span of the simulation.                                                                 |\n",
    "| `sim_num`      | Integer: Number of simulation runs to perform.                                                            |\n",
    "| `time_step`    | Float: Time step size used for approximating the continuous-time model.                                    |\n",
    " \n",
    "### Output\n",
    "| **Variable**   | **Description**                                                                                           |\n",
    "|----------------|-----------------------------------------------------------------------------------------------------------|\n",
    "| `X_matrix`     | `np.array` of shape `(sim_num, sim_time, 2)`. Stores the state variable \\( X_t \\) for each simulation run and time step. Each entry is an `np.array` representing \\( X_t \\). |\n",
    "| `M_matrix`     | `np.array` of shape `(sim_num, sim_time, 2)`. Stores the perturbation direction \\( M_t \\) for each simulation run and time step. Each entry is an `np.array` representing \\( M_t \\). |\n",
    "| `L_matrix`     | `np.array` of shape `(sim_num, sim_time)`. Stores the jump state \\( L_t \\) (as an integer) for each simulation run and time step. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_simulation(lom, drift_adj, P_trans, X0, M0, L0, num_shock, sim_time, sim_num, time_step): \n",
    "\n",
    "    #########################################################################\n",
    "    # This code uses law of motion of state variables to simulate evolutions of state variables and response to an initial purturbation to one state using different random seeds. \n",
    "    #########################################################################\n",
    "    \n",
    "    #########################################################################\n",
    "    # Input variables: \n",
    "    #\n",
    "    # lom         - function: Law of motion for X_t and M_t. The next states, \n",
    "    #               X_{t+1} and M_{t+1}, are determined by lom(X_t, M_t, W_t, L_t).\n",
    "    # drift_adj   - function: Drift distortion function. Determines the drift term, \n",
    "    #               mu_t = drift_adj(X_t, L_t).\n",
    "    # P_trans     - function: Transition probability for L_t. The transition \n",
    "    #               probability P is given by P_trans(X_t, W_t).\n",
    "    # X0          - np.array: Initial state of the state variable X_t.\n",
    "    # M0          - np.array: Initial perturbation direction vector.\n",
    "    # L0          - integer: Initial state of the jump variable L_t.\n",
    "    # num_shock   - integer: Dimension of the shock variable W_t.\n",
    "    # sim_time    - float: Total time span of the simulation.\n",
    "    # sim_num     - integer: Number of simulation runs to perform.\n",
    "    # time_step   - float: Time step size used for approximating the continuous-time model.\n",
    "    ######################################################################### \n",
    "    \n",
    "    #########################################################################\n",
    "    # Output variables: \n",
    "    # X_matrix    - np.array of shape (sim_num, sim_time, 2). Stores the state \n",
    "    #               variable X_t for each simulation run and time step. Each \n",
    "    #               entry is an np.array representing X_t.\n",
    "    # M_matrix    - np.array of shape (sim_num, sim_time, 2). Stores the \n",
    "    #               perturbation direction M_t for each simulation run and \n",
    "    #               time step. Each entry is an np.array representing M_t.\n",
    "    # L_matrix    - np.array of shape (sim_num, sim_time). Stores the jump \n",
    "    #               state L_t (as an integer) for each simulation run and time step.\n",
    "    #########################################################################\n",
    "\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        futures = [executor.submit(simulate_single_process, n, lom, drift_adj, P_trans, X0, M0, L0, num_shock, sim_time, time_step) for n in tqdm(range(sim_num), desc=\"Submitting tasks\")]\n",
    "        results = []\n",
    "        success_count = 0 \n",
    "        fail_count_z = 0 \n",
    "        for future in tqdm(as_completed(futures), total=sim_num, desc=\"Processing tasks\"): \n",
    "            result = future.result() \n",
    "            results.extend(result)\n",
    "\n",
    "\n",
    "        if not results:\n",
    "            return None, None\n",
    "\n",
    "        X_matrix, M_matrix, L_matrix = zip(*results) \n",
    "\n",
    "        return X_matrix, M_matrix, L_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2 Value Decomposition\n",
    "\n",
    "We interpret the partial derivative of the value function with respect to the R\\&D knowledge state as an asset price. As such, it has four payoff contributions as we have derived previously:\n",
    "\n",
    "1. $\\delta m \\cdot \\frac{\\partial U}{\\partial x}$;\n",
    "2. $m \\cdot \\sum_{\\ell=1}^L \\frac{\\partial {\\mathcal J}^\\ell}{\\partial x} g^{\\ell*} (V^\\ell - V)$;\n",
    "3. $m \\cdot \\sum_{\\ell=1}^L {\\mathcal J}^\\ell g^{\\ell*} \\frac{\\partial V^\\ell}{\\partial x}$;\n",
    "4. $\\xi m \\cdot \\sum_{\\ell=1}^L \\frac{\\partial {\\mathcal J}^\\ell}{\\partial x} (1 - g^{\\ell*} + g^{\\ell*} \\log g^{\\ell*})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also consider four different configurations of uncertainty aversion as a way to assess the different economic forces in play:\n",
    "\n",
    "1. pre-jump neutrality - post-jump neutrality;\n",
    "2. pre-jump neutrality - post-jump aversion;\n",
    "3. pre-jump aversion - post-jump neutrality;\n",
    "4. pre-jump aversion - post-jump aversion.\n",
    "\n",
    "We include cases b) and c) because they provide revealing intermediate cases that help understand the overall uncertainty implications. For instance, there are two forces in play. First, uncertainty about when the new technology will be realized would seem to make investment in R\\&D less attractive. Second, the positive implications for a technological success can be stronger when there is more aversion to this uncertainty. Intermediate case c) allows us to feature more the first force, while intermediate case b) shifts attention to the second force. With these intermediate cases, we can better assess the quantitative magnitude of these offsetting forces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R&D technology discovery channel with $\\xi = 0.15$ \n",
    "\n",
    "| Case                     | i    | ii   | iii(dc) | iii(td) | iv    | sum     |\n",
    "|---------------------------|------|------|---------|---------|-------|---------|\n",
    "| pre neutrality            |      |      |         |         |       |         |\n",
    "| a) post neutrality         | 0.00186 | 0.01287 | 0.01356  | 0.00173 | 0.00000 | 0.03003 |\n",
    "| b) post aversion           | 0.00261 | 0.01610 | 0.01570  | 0.00264 | 0.00000 | 0.03705 |\n",
    "| pre aversion               |      |      |         |         |       |         |\n",
    "| c) post neutrality         | 0.00190 | 0.00960 | 0.01598  | 0.00124 | 0.00241 | 0.03113 |\n",
    "| d) post aversion           | 0.00272 | 0.01104 | 0.01999  | 0.00177 | 0.00387 | 0.03962 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  R&D technology discovery channel with $\\xi = 0.075$\n",
    "\n",
    "|                         | i           | ii           | iii(dc)      | iii(td)      | iv           | sum          |\n",
    "|------------------------- |-------------|--------------|--------------|--------------|--------------|--------------|\n",
    "| **pre neutrality**       |             |              |              |              |              |              |\n",
    "| a) post neutrality       | 0.001857218 | 0.012873257  | 0.013560828  | 0.001734671  | 0.000000004  | 0.030026     |\n",
    "| b) post aversion         | 0.003518361 | 0.020756782  | 0.017129194  | 0.003902445  | 0.000000012  | 0.045307     |\n",
    "| **pre aversion**         |             |              |              |              |              |              |\n",
    "| c) post neutrality       | 0.001901772 | 0.006724568  | 0.018433624  | 0.000809961  | 0.004229411  | 0.032099     |\n",
    "| d) post aversion         | 0.003383954 | 0.006335223  | 0.029402412  | 0.001150690  | 0.010221146  | 0.050493     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ###  R&D technology discovery channel with $\\xi = 0.005$\n",
    " \n",
    "|                         | i           | ii           | iii(dc)      | iii(td)      | iv           | sum          |\n",
    "|------------------------- |-------------|--------------|--------------|--------------|--------------|--------------|\n",
    "| **pre neutrality**       |             |              |              |              |              |              |\n",
    "| post neutrality          | 0.001857218 | 0.012873257  | 0.013560828  | 0.001734671  | 0.000000004  | 0.030026     |\n",
    "| post aversion            | 0.009626521 | 0.071895016  | 0.001216563  | 0.022364848  | 0.000000171  | 0.105103     |\n",
    "| **pre aversion**         |             |              |              |              |              |              |\n",
    "| post neutrality          | 0.001338064 | -0.000342846 | 0.023794618  | 0.000000000  | 0.001459983  | 0.026249     |\n",
    "| post aversion            | -0.001285934| -0.000179618 | 0.010892420  | 0.000000000  | 0.002009618  | 0.011436     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All four channels are activated with $\\xi = 0.15$ \n",
    "\n",
    "|                         | i           | ii           | iii(dc)      | iii(td)      | iv           | sum          |\n",
    "|------------------------- |-------------|--------------|--------------|--------------|--------------|--------------|\n",
    "| **pre neutrality**       |             |              |              |              |              |              |\n",
    "| a) post neutrality       | 0.001857218 | 0.012873257  | 0.013560828  | 0.001734671  | 0.000000004  | 0.030026     |\n",
    "| b) post aversion         | 0.002589657 | 0.015145588  | 0.015750393  | 0.002774305  | 0.000000007  | 0.036260     |\n",
    "| **pre aversion**         |             |              |              |              |              |              |\n",
    "| c) post neutrality       | 0.002056726 | 0.009885185  | 0.016963779  | 0.001264800  | 0.002905626  | 0.033076     |\n",
    "| d) post aversion         | 0.003053070 | 0.010126330  | 0.021902142  | 0.002065545  | 0.004583659  | 0.041731     |\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2 Expected Marginal Social Payoffs for Alternative Horizons\n",
    "\n",
    "As we demonstrated, the derivative of the value function has the interpretation as a stochastically discounted social cash flow, with the four contributions given at the outset of Section 3.3. The \"stochastic discount factor\" includes the vector of stochastic impulse responses, the process $M$, along with the subjective rate of discount, $\\delta$. The following figure shows the period-by-period contribution for each of the four components.\n",
    "\n",
    "Both of the continuation value contributions to the social cash flow, terms ii) and iii), are important contributors to the marginal value of R\\&D, but there are substantial differences in their horizon dependence. Term ii) has an important initial contribution that then gradually vanishes so that by a thirty-year horizon it is between one fourth and a third of its initial impact, depending on the uncertainty configuration. In contrast, term iii) is initially very small but has a substantial peak effect by year thirty. Both contributions are enhanced by post-jump uncertainty aversion. Its impact on marginal valuation remains important well past a horizon of forty years, reflecting the long-term nature of the valuation. The direct marginal utility contribution, term i), is small across all horizons, although it does increase up to twenty years. The entropy contribution, term iv), is also relatively minor across all horizons and uncertainty aversion configurations, though the initial magnitude is augmented by pre-jump uncertainty aversion, and this effect persists out to thirty years.\n",
    "\n",
    "\n",
    "In summary, the more skeptical assessment of R\\&D prospects prior to a jump induces only a quantitatively minor adverse impact on the incentive for R\\&D investment. A possible R\\&D success, however, gives a quantitatively important incentive for more R\\&D investment. While these quantitative results are special and tied to our model calibration, these competing forces are likely to be in play in more general circumstances.\n",
    "\n",
    "### Remark\n",
    "\n",
    "Recall that this is “big project” R\\&D analogous perhaps to the Manhattan Project or the Apollo program, with uncertainty in the R\\&D investment only about the timing of a successful outcome or social payoff. For the reasons we have discussed, more R\\&D leads to an increased likelihood that the new, clean technology will be discovered sooner, even though the uncertainty in the technology may be greater. This increase in a more uncertain investment stands in contrast to a standard portfolio allocation problem with riskless and uncertain investment alternatives. In this latter problem, an enhanced concern about uncertainty leads to a reduction in the portfolio weight associated with the uncertain investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
